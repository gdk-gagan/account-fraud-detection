{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31049777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipynb\n",
    "# from ipynb.fs.full.feature_engineering import make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecece8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7115618",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 2-Feature-Engineering.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3595d81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['count_feat_0', 'count_feat_1', 'count_feat_2', 'count_feat_3',\n",
       "       'count_feat_4', 'count_feat_5', 'count_feat_6', 'count_feat_7',\n",
       "       'count_feat_8', 'count_feat_9', 'count_feat_10', 'count_feat_11',\n",
       "       'count_feat_12', 'count_feat_13', 'count_feat_14', 'count_feat_15',\n",
       "       'interaction_feat_2', 'interaction_feat_3', 'anomaly_feat_0',\n",
       "       'anomaly_feat_1', 'anomaly_feat_2', 'anomaly_feat_3',\n",
       "       'interaction_feat_0', 'interaction_feat_1', 'device_feat_1_0',\n",
       "       'device_feat_1_1', 'device_feat_1_2', 'device_feat_1_3',\n",
       "       'device_feat_1_4', 'device_feat_2_0', 'device_feat_2_1',\n",
       "       'device_feat_2_2', 'device_feat_2_3', 'device_feat_2_4',\n",
       "       'device_feat_2_5', 'device_feat_2_6', 'device_feat_2_7',\n",
       "       'device_feat_2_8', 'device_feat_2_9', 'device_feat_2_10',\n",
       "       'device_feat_2_11'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14cf209d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anomaly_feat_0', 'anomaly_feat_1', 'anomaly_feat_2', 'anomaly_feat_3',\n",
       "       'count_feat_0', 'count_feat_1', 'count_feat_2', 'count_feat_3',\n",
       "       'count_feat_4', 'count_feat_5', 'count_feat_6', 'count_feat_7',\n",
       "       'count_feat_8', 'count_feat_9', 'count_feat_10', 'count_feat_11',\n",
       "       'count_feat_12', 'count_feat_13', 'count_feat_14', 'count_feat_15',\n",
       "       'interaction_feat_0', 'interaction_feat_1', 'interaction_feat_2',\n",
       "       'interaction_feat_3', 'device_feat_1_0', 'device_feat_1_1',\n",
       "       'device_feat_1_2', 'device_feat_1_3', 'device_feat_1_4',\n",
       "       'device_feat_2_0', 'device_feat_2_1', 'device_feat_2_2',\n",
       "       'device_feat_2_3', 'device_feat_2_4', 'device_feat_2_5',\n",
       "       'device_feat_2_6', 'device_feat_2_7', 'device_feat_2_8',\n",
       "       'device_feat_2_9', 'device_feat_2_10'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adb0fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to implement Logistic Regression, Random Forest, XGboost, SVM and Neural Network and output precision, recall, confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccfbe315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_pipeline(X_train, X_test, y_train, y_test):\n",
    " \n",
    "    # Create a dictionary to store models\n",
    "    models = {\n",
    "        'Random Forest': RandomForestClassifier(),\n",
    "        'XGBoost': XGBClassifier(),\n",
    "        'Logistic Regression': LogisticRegression(),\n",
    "        'Neural Network': MLPClassifier()\n",
    "    }\n",
    "    \n",
    "    # Initialize lists to store accuracy and pr-auc\n",
    "    accuracy_scores = []\n",
    "    pr_auc_scores = []\n",
    "    \n",
    "    # Loop through each model\n",
    "    for model_name, model in models.items():\n",
    "        # Perform cross-validation\n",
    "        accuracy = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        accuracy_scores.append((model_name, np.mean(accuracy)))\n",
    "        \n",
    "        # Fit the model on the full training set\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict probabilities on the test set\n",
    "        y_probs = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Calculate precision-recall curve values\n",
    "        precision, recall, _ = precision_recall_curve(y_test, y_probs)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        pr_auc_scores.append((model_name, pr_auc))\n",
    "        \n",
    "        # Plot PR-curve\n",
    "        plt.plot(recall, precision, label=f'{model_name} (AUC = {pr_auc:.2f})')\n",
    "\n",
    "    # Plot accuracy scores\n",
    "    accuracy_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    best_model_name, _ = accuracy_scores[0]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for model_name, accuracy in accuracy_scores:\n",
    "        plt.bar(model_name, accuracy, color='skyblue')\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Validation Accuracy for Each Model')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print best model\n",
    "    print(f'Best Model: {best_model_name}')\n",
    "    \n",
    "    # Print classification report for the best model\n",
    "    best_model = models[best_model_name]\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Plot PR-curve for the best model\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4945b914",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- device_feat_2_11\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclassification_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 25\u001b[0m, in \u001b[0;36mclassification_pipeline\u001b[0;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Predict probabilities on the test set\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m y_probs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Calculate precision-recall curve values\u001b[39;00m\n\u001b[1;32m     28\u001b[0m precision, recall, _ \u001b[38;5;241m=\u001b[39m precision_recall_curve(y_test, y_probs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mastercard/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:862\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    860\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    861\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    865\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mastercard/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 602\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mastercard/lib/python3.9/site-packages/sklearn/base.py:548\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    485\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    490\u001b[0m ):\n\u001b[1;32m    491\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \n\u001b[1;32m    493\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    551\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    552\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    553\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    554\u001b[0m         )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mastercard/lib/python3.9/site-packages/sklearn/base.py:481\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    477\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    479\u001b[0m     )\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- device_feat_2_11\n"
     ]
    }
   ],
   "source": [
    "classification_pipeline(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e45b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
